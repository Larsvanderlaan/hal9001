% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hal.R
\name{fit_hal}
\alias{fit_hal}
\title{HAL: The Highly Adaptive Lasso}
\usage{
fit_hal(
  X,
  Y,
  X_unpenalized = NULL,
  max_degree = 3,
  smoothness_orders = rep(0, ncol(X)),
  num_knots = sapply(1:max_degree, function(d) {     round(500/d) }),
  fit_type = c("glmnet", "lassi"),
  n_folds = 10,
  foldid = NULL,
  use_min = TRUE,
  reduce_basis = NULL,
  family = c("gaussian", "binomial", "poisson", "cox"),
  return_lasso = TRUE,
  return_x_basis = FALSE,
  basis_list = NULL,
  lambda = NULL,
  id = NULL,
  offset = NULL,
  cv_select = TRUE,
  adaptive_smoothing = FALSE,
  ...,
  yolo = TRUE
)
}
\arguments{
\item{X}{An input \code{matrix} containing observations and covariates.}

\item{Y}{A \code{numeric} vector of obervations of the outcome variable.}

\item{X_unpenalized}{An input \code{matrix} with the same format as X, that
directly get appended into the design matrix (no basis expansion). No L1
penalization is performed on these covariates.}

\item{max_degree}{The highest order of interaction terms for which the basis
functions ought to be generated. The default (\code{NULL}) corresponds to
generating basis functions for the full dimensionality of the input matrix.
@param smoothness_orders An \code{integer} vector of length 1 or length ncol(\code{X}).
If \code{smoothness_orders} is of length 1 then its values are recycled to form a vector of length length ncol(\code{X}).
Given such a vector of length ncol(\code{X}), the ith element specifies the level of smoothness for the variable
corresponding with the ith column in \code{X}.
A value of "0" corresponds with 0-order splines (piece-wise constant) which assumes no smoothness or continuity of true regression function.
A value of "1" corresponds with 1-order splines (piece-wise linear) which only assumes continuity of true regression function.
A value of "2" corresponds with 2-order splines (piece-wise quadratic and linear terms) which assumes one order of differentiability for the true regression function.
Warning: if \code{smoothness_orders} has length less than ncol(\code{X}) then values are recycled as needed.
@param num_knots An \code{integer} vector of length 1 or length \code{max_degree}.
If \code{num_knots} is a vector of length 1 then its values are recycled to produce a vector of length \code{max_degree}.
Given a possibly recycled vector of length \code{max_degree},
num_knots[i] specifies the maximum number of knot points used when generating basis functions of degree i for each covariate.
For example, num_knots[1] specifies how many knot points to use when generating main-term additive basis functions.
num_knots[2] specifies how many knot points should be used when generating each univariate basis function in the 2-tensor product basis functions.
A smaller number of knot points gives rise to a less smooth function. However, fewer knot points can significantly decrease runtime.
If smoothness_orders is 1 or higher then few knot points (10-30) are needed to maintain near optimal performance. For smoothness_orders = 0, too few knot points (< 50) can significantly reduce performance.
We recommend specifying a vector of length \code{max_degree} that decreases exponentially to prevent combinatorical explosions in the number of higher degree interaction basis functions generated.
Recommended settings for no cost in performance:
If smoothness_orders = 0 and max_degree = 3, num_knots = c(400, 200, 100).
If smoothness_orders = 1 or higher and max_degree = 3, num_knots = c(100, 75, 50).
Recommended settings for fairly fast runtime and great performance:
If smoothness_orders = 0 and max_degree = 3, num_knots = c(200, 100, 50).
If smoothness_orders = 1 or higher and max_degree = 3, num_knots = c(50, 25, 15).
Recommended settings for fast runtime and good/great performance:
If smoothness_orders = 0 and max_degree = 3, num_knots = c(100, 50, 25).
If smoothness_orders = 1 or higher and max_degree = 3, num_knots = c(40, 15, 10).
Recommended settings for very fast runtime and good performance:
If smoothness_orders = 0 and max_degree = 3, num_knots = c(50, 25, 10).
If smoothness_orders = 1 or higher and max_degree = 3, num_knots = c(25, 10, 5).}

\item{fit_type}{The specific routine to be called when fitting the Lasso
regression in a cross-validated manner. Choosing the \code{glmnet} option
will result in a call to \code{\link[glmnet]{cv.glmnet}} while \code{lassi}
will produce a (faster) call to a custom Lasso routine.}

\item{n_folds}{Integer for the number of folds to be used when splitting the
data for V-fold cross-validation. This defaults to 10.}

\item{foldid}{An optional \code{numeric} containing values between 1 and
\code{n_folds}, identifying the fold to which each observation is assigned.
If supplied, \code{n_folds} can be missing. In such a case, this vector is
passed directly to \code{\link[glmnet]{cv.glmnet}}.}

\item{use_min}{Specify lambda selected by \code{\link[glmnet]{cv.glmnet}}.
\code{TRUE}, \code{"lambda.min"} is used; otherwise, \code{"lambda.1se"}.}

\item{reduce_basis}{A \code{numeric} value bounded in the open interval
(0,1) indicating the minimum proportion of 1's in a basis function column
needed for the basis function to be included in the procedure to fit the
Lasso. Any basis functions with a lower proportion of 1's than the cutoff
will be removed. This argument defaults to \code{NULL}, in which case all
basis functions are used in the lasso-fitting stage of the HAL algorithm.}

\item{family}{A \code{character} corresponding to the error family for a
generalized linear model. Options are limited to "gaussian" for fitting a
standard linear model, "binomial" for penalized logistic regression,
"poisson" for penalized Poisson regression, and "cox" for a penalized
proportional hazards model. Note that in all cases where family is not set
to "gaussian", \code{fit_type} is limited to "glmnet". In future, aribtrary
outcome types may be supported by passed in a \code{\link[stats]{family}}
objects (e.g., \code{\link[stats]{quasibinomial}}), which could be passed
through to \code{\link[glmnet]{glmnet}} or \code{\link[glmnet]{cv.glmnet}}.}

\item{return_lasso}{A \code{logical} indicating whether or not to return
the \code{glmnet} fit of the lasso model.}

\item{return_x_basis}{A \code{logical} indicating whether or not to return
the matrix of (possibly reduced) basis functions used in the HAL lasso fit.}

\item{basis_list}{The full set of basis functions generated from the input
data X (via a call to \code{enumerate_basis}). The dimensionality of this
structure is dim = (n * 2^(d - 1)), where n is the number of observations
and d is the number of columns in X.}

\item{lambda}{User-specified array of values of the lambda tuning parameter
of the Lasso L1 regression. If \code{NULL}, \code{\link[glmnet]{cv.glmnet}}
will be used to automatically select a CV-optimal value of this
regularization parameter. If specified, the Lasso L1 regression model will
be fit via \code{glmnet}, returning regularized coefficient values for each
value in the input array.}

\item{id}{a vector of ID values, used to generate cross-validation folds for
cross-validated selection of the regularization parameter lambda.}

\item{offset}{a vector of offset values, used in fitting.}

\item{cv_select}{A \code{logical} specifying whether the array of values
specified should be passed to \code{\link[glmnet]{cv.glmnet}} in order to
pick the optimal value (based on cross-validation) (when set to
\code{TRUE}) or to simply fit along the sequence of values (or single
value) using \code{\link[glmnet]{glmnet}} (when set to \code{FALSE}).}

\item{...}{Other arguments passed to \code{\link[glmnet]{cv.glmnet}}. Please
consult its documentation for a full list of options.
@param adaptive_smoothing A \code{boolean} which if true HAL will perform adaptive smoothing up until the maximum order of smoothness specified by \ref{smoothness_orders}.
For example, if smoothness_orders = 2 and adaptive_smoothing = TRUE then HAL will generate all basis functions of smoothness order 0, 1, and 2, and data-adaptively select the basis functions to use.
Warning: This can increase runtime by a factor of 2-3+ depending on value of \code{smoothness_orders}.}

\item{yolo}{A \code{logical} indicating whether to print one of a curated
selection of quotes from the HAL9000 computer, from the critically
acclaimed epic science-fiction film "2001: A Space Odyssey" (1968).}
}
\value{
Object of class \code{hal9001}, containing a list of basis
 functions, a copy map, coefficients estimated for basis functions, and
 timing results (for assessing computational efficiency).
}
\description{
Estimation procedure for HAL, the Highly Adaptive Lasso
}
\details{
The procedure uses a custom C++ implementation to generate a design
 matrix consisting of basis functions corresponding to covariates and
 interactions of covariates and to remove duplicate columns of indicators.
 The Lasso regression is fit to this (usually) very wide matrix using either
 a custom implementation (based on \pkg{origami}) or by a call to
 \code{\link[glmnet]{cv.glmnet}}.
}
\examples{
\donttest{
n <- 100
p <- 3
x <- xmat <- matrix(rnorm(n * p), n, p)
y_prob <- plogis(3 * sin(x[, 1]) + sin(x[, 2]))
y <- rbinom(n = n, size = 1, prob = y_prob)
ml_hal_fit <- fit_hal(X = x, Y = y, family = "binomial", yolo = FALSE)
preds <- predict(ml_hal_fit, new_data = x)
}

}
